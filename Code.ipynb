{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark as ps # for the pyspark suite\n",
    "import warnings         # for displaying warning\n",
    "\n",
    "#Initiate a SparkSession. A SparkSession embeds both a SparkContext and \n",
    "#a SQLContext to use RDD-based and DataFrame-based functionalities of Spark.\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"df lecture\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from string import Template\n",
    "\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 - \n",
    "\n",
    "#### Importing and Loading the data\n",
    "I have used .csv file format to store given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "media_df = spark.read.csv(\"data/media.csv\",header=True,sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+----------+----+---------+\n",
      "| STB|      TITLE|   PROVIDER|      DATE| REV|VIEW_TIME|\n",
      "+----+-----------+-----------+----------+----+---------+\n",
      "|stb1| the matrix|warner bros|2014-04-01|4.00|     1:30|\n",
      "|stb1|unbreakable|buena vista|2014-04-03|6.00|     2:05|\n",
      "|stb2| the hobbit|warner bros|2014-04-02|8.00|     2:45|\n",
      "|stb3| the matrix|warner bros|2014-04-02|4.00|     1:05|\n",
      "+----+-----------+-----------+----------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "media_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STB: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- PROVIDER: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- REV: string (nullable = true)\n",
      " |-- VIEW_TIME: string (nullable = true)\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "media_df.printSchema()\n",
    "\n",
    "print(media_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STB: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- PROVIDER: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- REV: integer (nullable = true)\n",
      " |-- VIEW_TIME: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To perform the aggregate functions on REV column convert string datatype to Integer --> for question 2.2\n",
    "media_df = media_df.withColumn(\"REV\", media_df[\"REV\"].cast(IntegerType()))\n",
    "media_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create view to access data from spark sql\n",
    "media_df.createOrReplaceTempView(\"media_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+----------+---+---------+\n",
      "| STB|      TITLE|   PROVIDER|      DATE|REV|VIEW_TIME|\n",
      "+----+-----------+-----------+----------+---+---------+\n",
      "|stb1|unbreakable|buena vista|2014-04-03|  6|     2:05|\n",
      "|stb2| the hobbit|warner bros|2014-04-02|  8|     2:45|\n",
      "+----+-----------+-----------+----------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"SELECT STB,TITLE,PROVIDER ,DATE, REV,VIEW_TIME FROM media_business where REV >= 5.0 order by PROVIDER LIMIT 5\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------------+\n",
      "|      TITLE|sum(REV)|count(DISTINCT STB)|\n",
      "+-----------+--------+-------------------+\n",
      "| the hobbit|       8|                  1|\n",
      "|unbreakable|       6|                  1|\n",
      "| the matrix|       8|                  2|\n",
      "+-----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#/query -s TITLE,REV:sum,STB:collect -g TITLE\n",
    "\n",
    "result = spark.sql(\"SELECT TITLE, sum(REV),count(distinct(STB)) FROM media_business group by TITLE\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|     TITLE|REV|\n",
      "+----------+---+\n",
      "|the hobbit|  8|\n",
      "|the matrix|  4|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = spark.sql(\"SELECT TITLE, REV FROM media_business WHERE DATE ='2014-04-02' AND (TITLE = 'the hobbit' OR TITLE = 'the matrix')\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Function_Param():\n",
    "    '''Data Wrangling : This class is created to extract select,oderby, filter, groupby, \n",
    "    aggregate and boolean functions and extract respective column names'''\n",
    "    \n",
    "    \n",
    "    def get_string(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Given one string returns the list of strings.\n",
    "            '''\n",
    "        string =string.split()\n",
    "        return string\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def find_parameters(value, items):\n",
    "        '''\n",
    "                INPUT: function name:string and user input string in tokenized list format.\n",
    "                OUTPUT: list\n",
    "                To get the parameters for each function like select, order by, filter & group by\n",
    "            '''\n",
    "        i = items.index(value)\n",
    "        return items[i+1]\n",
    "    \n",
    "    \n",
    "    def fetch_select_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract select function parameters in list.\n",
    "            '''\n",
    "        # get the maching function in variable\n",
    "        s_matching = [s for s in string if \"-s\" in s]\n",
    "        if s_matching!=[]:\n",
    "            s_param =Function_Param.find_parameters(\"-s\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return s_param\n",
    "    \n",
    "    def fetch_order_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract orderby function parameters in list.\n",
    "            '''\n",
    "        o_matching = [o for o in string if \"-o\" in o]\n",
    "        if o_matching!=[]:\n",
    "            o_param =find_parameters(\"-o\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return o_param\n",
    "        \n",
    "    def fetch_filter_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract filter function parameters in list.\n",
    "            '''\n",
    "        f_matching = [f for f in string if \"-f\" in f]\n",
    "        if f_matching != []:\n",
    "            f_param =find_parameters(\"-f\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return f_param\n",
    "    \n",
    "    def fetch_groupby_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract group by function parameters in list.\n",
    "            '''\n",
    "        g_matching = [g for g in string if \"-g\" in g]\n",
    "        if g_matching !=[]:\n",
    "            g_param =find_parameters(\"-g\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return g_param\n",
    "\n",
    "    def fetch_filter_param_strval(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract filter function for the columns whose values are descriptive with 1 white \n",
    "                space parameters in list.\n",
    "            '''\n",
    "        f_matching = [f for f in string if \"-f\" in f]\n",
    "        if f_matching != []:\n",
    "            f_param =find_parameters_filter_boolean_strval(\"-f\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return f_param\n",
    "   \n",
    "    def fetch_OR_boolean_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract boolean or function columns names in list.\n",
    "            '''\n",
    "        b_matching = [b for b in string if \"OR\" in b]\n",
    "        if b_matching2 !=[]:\n",
    "            b_param =find_parameters(\"OR\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return b_param\n",
    "    \n",
    "    def fetch_AND_boolean_param(string):\n",
    "        '''\n",
    "                INPUT: string\n",
    "                OUTPUT: list\n",
    "                Extract boolean and function columns names in list.\n",
    "            '''\n",
    "        a_matching = [a for a in string if \"AND\" in a]\n",
    "        if a_matching1 !=[]:\n",
    "            a_param =find_parameters(\"AND\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return a_param\n",
    "    \n",
    "   # converts select function list of column names/parameters to each column name variable \n",
    "    def select_columnnames(s_param):\n",
    "        \n",
    "            \n",
    "        for n, val in enumerate(s_param):\n",
    "            globals()[\"s_column%d\"%n] = val\n",
    "            \n",
    "    # converts orderby function list of column names/parameters to each column name variable \n",
    "    def orderby_columnnames(o_param):\n",
    "        for n, val in enumerate(o_param):\n",
    "            globals()[\"o_column%d\"%n] = val\n",
    "            \n",
    "     # converts group by function list of column names/parameters to each column name variable    \n",
    "    def groupby_columnnames(g_param):\n",
    "        for n, val in enumerate(g_param):\n",
    "            globals()[\"g_column%d\"%n] = val\n",
    "    \n",
    "     # converts filter function list of column names/parameters to each column name variable    \n",
    "    def filter_columnnames(f_param):\n",
    "        f_column = (\",\".join(s for s in f_param if \"=\".lower() in s.lower())).split(\"=\",2)\n",
    "        if f_column !=\"\":\n",
    "            return f_column[0],f_column[1]\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "    # converts aggregate function list of column names/parameters to each column name variable       \n",
    "    def agg_columnnames(ag_param):\n",
    "        for n, val in enumerate(ag_param):\n",
    "            globals()[\"ag_column%d\"%n] = val\n",
    "            \n",
    "    # converts boolean AND list of column names/parameters to each column name variable       \n",
    "    def and_columnnames(a_param):\n",
    "        a_column = (\",\".join(s for s in a_param if \"=\" in s.lower())).split(\"=\",2)\n",
    "        if a_column !=\"\":\n",
    "            return a_column[0],a_column[1]\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "    # converts boolean OR list of column names/parameters to each column name variable       \n",
    "    def or_columnnames(b_param):\n",
    "        b_column = (\",\".join(s for s in b_param if \"=\" in s.lower())).split(\"=\",2)\n",
    "        if b_column !=\"\":\n",
    "            return b_column[0],b_column[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    # aggregate function -sum - column names are returned as column name , aggregate function name respectively    \n",
    "    def agg_sum_param(s_param):\n",
    "        sum_col = (\",\".join(s for s in s_param if \":sum\".lower() in s.lower()))\n",
    "        sum_col =sum_col.split(\":\",2)\n",
    "        if sum_col !=\"\":\n",
    "            return sum_col[0],sum_col[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    # aggregate function -min - column names are returned as column name , aggregate function name respectively    \n",
    "    def agg_min_param(s_param):\n",
    "        min_col = (\",\".join(s for s in s_param if \":min\".lower() in s.lower())).split(\":\",2)\n",
    "        if min_col !=\"\":\n",
    "            return min_col[0],min_col[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "     # aggregate function -max - column names are returned as column name , aggregate function name respectively    \n",
    "    def agg_max_param(s_param):\n",
    "        max_col = (\",\".join(s for s in s_param if \":max\".lower() in s.lower())).split(\":\",2)\n",
    "        if max_col !=\"\":\n",
    "            return max_col[0],max_col[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    # aggregate function -count - column names are returned as column name , aggregate function name respectively        \n",
    "    def agg_count_param(s_param):\n",
    "        count_col = (\",\".join(s for s in s_param if \":count\".lower() in s.lower())).split(\":\",2)\n",
    "        if count_col !=\"\":\n",
    "            return count_col[0],count_col[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "     # aggregate function -collect - column names are returned as column name , aggregate function name respectively    \n",
    "    def agg_collect_param(s_param):\n",
    "        collect_col = (\",\".join(s for s in s_param if \":COLLECT\".lower() in s.lower())).split(\":\",2)\n",
    "        if collect_col !=\"\":\n",
    "            return collect_col[0],collect_col[1]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    # to get the values of functions which has string values with one space\n",
    "    def find_parameters_filter_boolean_strval(value, items):\n",
    "        i = items.index(value)\n",
    "        x =(\" \".join(s for s in items[i+1:i+3]))\n",
    "        return x\n",
    "    \n",
    "     \n",
    "    def fetch_OR_boolean_param_strval(string):\n",
    "        b_matching = [b for b in string if \"OR\" in b]\n",
    "        if b_matching !=[]:\n",
    "            b_param =find_parameters_filter_boolean_strval(\"OR\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return b_param\n",
    "    \n",
    "     # to get the values of functions which has string values with one space\n",
    "    def fetch_AND_boolean_param_strval(string):\n",
    "        a_matching = [a for a in string if \"AND\" in a]\n",
    "        a_matching\n",
    "        if a_matching !=[]:\n",
    "            a_param =find_parameters_filter_boolean_strval(\"AND\",string).split(',')\n",
    "        else:\n",
    "            return\n",
    "        return a_param\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DML_Functions():\n",
    "    '''This class is created to build spark sql queries with select,oderby, filter, groupby, \n",
    "    aggregate and boolean functions '''\n",
    "    \n",
    "    def select_orderby(table_name, select_list,orderby_list):\n",
    "        '''\n",
    "        Returns the SQL query for computing column statistics.\n",
    "        Passing Input table_name, select function column names and \n",
    "        order by function column names.\n",
    "        '''\n",
    "        Function_Param.select_columnnames(selected_list)\n",
    "        Function_Param.orderby_columnnames(orderby_list)\n",
    "        query = '''SELECT ${s_col1}, ${s_col2},${s_col3}\n",
    "                   FROM ${table_name}\n",
    "        ORDER BY ${o_col1}, ${o_col2}'''\n",
    "        t = Template(query)\n",
    "        qry_template= t.substitute(s_col1 = s_column0, s_col2 = s_column1,s_col3 = s_column2,o_col1 = o_column0, o_col2 = o_column1, table_name=table_name)\n",
    "\n",
    "        return qry_template\n",
    "    \n",
    "    \n",
    "        #2.1\n",
    "    #Function Select_Filter\n",
    "    #./query -s TITLE,REV,DATE -f DATE=2014-04-01\n",
    "\n",
    "    def select_filter(table_name, selected_list,filter_list):\n",
    "        '''\n",
    "        Returns the SQL query for computing column statistics.\n",
    "        Passing Input table_name, select function column names and \n",
    "        filter/where clause column names.\n",
    "        '''\n",
    "        Function_Param.select_columnnames(selected_list)\n",
    "        f_column1,filter_value=Function_Param.filter_columnnames(filter_list)\n",
    "        if f_column1 == 'DATE':\n",
    "            filter_value = \"CAST('\"+ filter_value +\"' AS date)\"\n",
    "\n",
    "        query = '''SELECT ${s_col1}, ${s_col2},${s_col3}\n",
    "                   FROM ${table_name}\n",
    "                   WHERE ${f_column1} = ${filter_value}'''\n",
    "        t = Template(query)\n",
    "        qry_template= t.substitute(s_col1 = s_column0, s_col2 = s_column1,s_col3 = s_column2,f_column1=f_column1, table_name=table_name, filter_value=filter_value)  \n",
    "        return qry_template\n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_groupby_agg(table_name, selected_list,groupby_list,ag_col1,ag_funct1,ag_col2,ag_funct2):\n",
    "        '''\n",
    "        Returns the SQL for computing column statistics.\n",
    "        Passing Input table_name, select function column names, \n",
    "        group by function column names and aggregate functions and aggregrate function column names.\n",
    "        '''\n",
    "        Function_Param.select_columnnames(selected_list)\n",
    "        Function_Param.groupby_columnnames(groupby_list)\n",
    "        \n",
    "        \n",
    "\n",
    "        query = '''SELECT ${s_col1}, ${ag_funct1}(${ag_col1}),count(distinct(${ag_col2})) \n",
    "                    FROM ${table_name} \n",
    "                    group by ${g_column1}'''\n",
    "      \n",
    "        t = Template(query)\n",
    "        qry_template= t.substitute(s_col1 = s_column0,g_column1=g_column0, table_name=table_name,ag_col1=ag_col1,ag_funct1=ag_funct1,ag_col2=ag_col2,ag_funct2=ag_funct2)  \n",
    "        return qry_template\n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_advfilter_single_exp(table_name, selected_list,filter_list,operator_list,expression):\n",
    "        '''\n",
    "        Returns the SQL for computing column statistics.\n",
    "        Passing Input table_name, select function column names, \n",
    "        filter/where clause column names and boolean operators and boolean operators column names.\n",
    "        '''\n",
    "        Function_Param.select_columnnames(selected_list)\n",
    "        f_column1,filter_value=Function_Param.filter_columnnames(filter_list)\n",
    "        op_column1,op_value=Function_Param.or_columnnames(operator_list)\n",
    "        if f_column1 == 'DATE':\n",
    "            filter_value = \"CAST('\"+ filter_value +\"' AS date)\"\n",
    "        elif op_column1 == 'DATE':\n",
    "            op_value = \"CAST('\"+ op_value +\"' AS date)\"\n",
    "\n",
    "        query = '''SELECT ${s_col1}, ${s_col2}\n",
    "                   FROM ${table_name}\n",
    "                   WHERE ${f_column1} = ${filter_value} ${expression} ${op_column1} = ${op_value}'''\n",
    "        t = Template(query)\n",
    "        qry_template= t.substitute(s_col1 = s_column0, s_col2 = s_column1,f_column1=f_column1, table_name=table_name, filter_value=filter_value,op_column1=op_column1, expression=expression, op_value=op_value)  \n",
    "        return qry_template\n",
    "    \n",
    "    \n",
    "    def select_advfilter_double_exp(table_name, selected_list,filter_list,operator_list1,operator_list2,expression1,expression2):\n",
    "        '''\n",
    "        Returns the SQL for computing column statistics.\n",
    "        Passing Input table_name, select function column names, \n",
    "        filter/where clause column names and boolean operators and boolean operators column names.\n",
    "        '''\n",
    "        Function_Param.select_columnnames(selected_list)\n",
    "        f_column1,filter_value=Function_Param.filter_columnnames(filter_list)\n",
    "        op_column1,op_value1=Function_Param.and_columnnames(operator_list1)\n",
    "        op_column2,op_value2=Function_Param.or_columnnames(operator_list2)\n",
    "        if f_column1 == 'DATE':\n",
    "            filter_value = \"CAST('\"+ filter_value +\"' AS date)\"\n",
    "        elif op_column1 == 'DATE':\n",
    "            op_value = \"CAST('\"+ op_value +\"' AS date)\"\n",
    "        \n",
    "            \n",
    "        query = '''SELECT ${s_col1}, ${s_col2}\n",
    "                   FROM ${table_name}\n",
    "                   WHERE ${f_column1} = ${filter_value} ${expression1} (${op_column1} = ${op_value1} ${expression2} ${op_column2} = ${op_value2})'''\n",
    "        t = Template(query)\n",
    "        qry_template= t.substitute(s_col1 = s_column0, s_col2 = s_column1,f_column1=f_column1, table_name=table_name, filter_value=filter_value,op_column1=op_column1,op_column2=op_column2, expression1=expression1,expression2=expression2, op_value1=op_value1,op_value2=op_value2)  \n",
    "        return qry_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "###### The next task is to create a query tool that can execute simple queries against the datastore you created in step one.  The tool should accept command line args for SELECT, ORDER and FILTER functions:\n",
    "\n",
    "Created test case below for user input -->./query -s TITLE,REV,DATE -o DATE,TITLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Accept input string from user. Given input string is --> ./query -s TITLE,REV,DATE -o DATE,TITLE\n",
    "    string = str(input())\n",
    "    st = Function_Param.get_string(string)\n",
    "    selected_list =Function_Param.fetch_select_param(st)\n",
    "    ordered_list=Function_Param.fetch_order_param(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TITLE', 'REV', 'DATE'], ['DATE', 'TITLE'])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    selected_list,ordered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+\n",
      "|      TITLE|REV|      DATE|\n",
      "+-----------+---+----------+\n",
      "| the matrix|  4|2014-04-01|\n",
      "| the hobbit|  8|2014-04-02|\n",
      "| the matrix|  4|2014-04-02|\n",
      "|unbreakable|  6|2014-04-03|\n",
      "+-----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Creating the dynamic query by calling select_orderby function in DML_Functions class.\n",
    "    qry = DML_Functions.select_orderby('media_business',selected_list,ordered_list)\n",
    "\n",
    "    result = spark.sql(qry)\n",
    "    '''The result of Question 2.1 1st test case --> ./query -s TITLE,REV,DATE -o DATE,TITLE '''\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1\n",
    "For DML functions select & filter. \n",
    "Created test case for user input -->./query -s TITLE,REV,DATE -f DATE=2014-04-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Accept input string from user. Given input string is --> ./query -s TITLE,REV,DATE -f DATE=2014-04-01\n",
    "    string = str(input())\n",
    "    st = Function_Param.get_string(string)\n",
    "    selected_list =Function_Param.fetch_select_param(st)\n",
    "    filter_list=Function_Param.fetch_filter_param(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TITLE', 'REV:sum', 'STB:collect'], ['DATE=2014-04-01'])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    selected_list,filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|     TITLE|REV|      DATE|\n",
      "+----------+---+----------+\n",
      "|the matrix|  4|2014-04-01|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    qry = DML_Functions.select_filter('media_business',selected_list,filter_list)\n",
    "\n",
    "    result = spark.sql(qry)\n",
    "    '''The result of Question 2.1 2nd test case --> ./query -s TITLE,REV,DATE -f DATE=2014-04-01 '''\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "The next step is to add group by and aggregate functions to your query tool.  Your tool should support the following aggregates:\n",
    "Created below test case for user input --> ./query -s TITLE,REV:sum,STB:collect -g TITLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#./query -s TITLE,REV:sum,STB:collect -g TITLE\n",
    "string = str(input())\n",
    "st = Function_Param.get_string(string)\n",
    "selected_list =Function_Param.fetch_select_param(st)\n",
    "groupby_list=Function_Param.fetch_groupby_param(st)\n",
    "ag_col1,ag_funct1 = Function_Param.agg_sum_param(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TITLE', 'REV:sum', 'STB:collect'], ['TITLE'])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_list,groupby_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------------+\n",
      "|      TITLE|sum(REV)|count(DISTINCT STB)|\n",
      "+-----------+--------+-------------------+\n",
      "| the hobbit|       8|                  1|\n",
      "|unbreakable|       6|                  1|\n",
      "| the matrix|       8|                  2|\n",
      "+-----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qry = DML_Functions.select_groupby_agg('media_business',selected_list,groupby_list,'REV','sum','STB','collect')\n",
    "\n",
    "result = spark.sql(qry)\n",
    "'''The result of Question 2.2 test case --> ./query -s TITLE,REV:sum,STB:collect -g TITLE '''\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validating the answer using Spark df\n",
    "media_grp_df = media_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_agg = media_grp_df.groupby(\"TITLE\").\\\n",
    "    agg(\n",
    "        func.sum(\"REV\"),\n",
    "         func.countDistinct(\"STB\") \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------------+\n",
      "|      TITLE|sum(REV)|count(DISTINCT STB)|\n",
      "+-----------+--------+-------------------+\n",
      "| the hobbit|       8|                  1|\n",
      "|unbreakable|       6|                  1|\n",
      "| the matrix|       8|                  2|\n",
      "+-----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "Advanced filter function \n",
    "\n",
    "##### Using the single boolean operator  - \n",
    "Build the test case for user input -->\n",
    "./query -s TITLE,REV -f 'TITLE=\"the hobbit\" OR TITLE=\"the matrix\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input query string --> \"./query -s TITLE,REV -f TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "string = str(input())\n",
    "st = Function_Param.get_string(string)\n",
    "                               \n",
    "selected_list =Function_Param.fetch_select_param(st)\n",
    "filter_list=Function_Param.fetch_filter_param_strval(st)\n",
    "operator_list = Function_Param.fetch_OR_boolean_param_strval(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./query',\n",
       "  '-s',\n",
       "  'TITLE,REV',\n",
       "  '-f',\n",
       "  \"TITLE='the\",\n",
       "  \"hobbit'\",\n",
       "  'OR',\n",
       "  \"TITLE='the\",\n",
       "  \"matrix'\"],\n",
       " ['TITLE', 'REV'],\n",
       " [\"TITLE='the hobbit'\"],\n",
       " [\"TITLE='the matrix'\"])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st,selected_list,filter_list,operator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|      TITLE|REV|\n",
      "+-----------+---+\n",
      "| the matrix|  4|\n",
      "|unbreakable|  6|\n",
      "| the matrix|  4|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qry = DML_Functions.select_advfilter_single_exp('media_business',selected_list,filter_list,operator_list,'OR')\n",
    "result = spark.sql(qry)\n",
    "# Below is the result of question 2.3 with user input as \"./query -s TITLE,REV -f TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "\n",
    "Add a filter function which evaluates boolean AND and OR expressions in the following format:\n",
    "            STB=\"stb1\" AND TITLE=\"the hobbit\" OR TITLE=\"unbreakable\"\n",
    "            Assume AND has higher precedence than OR.  Parens can be added to change the above statement to the more logical:\n",
    "            STB=\"stb1\" AND (TITLE=\"the hobbit\" OR TITLE=\"unbreakable\")\n",
    "            \n",
    "            \n",
    "Advanced filter function. \n",
    "Using the double boolean operator  - \n",
    "Build the test case for user input -->\n",
    "\"./query -s TITLE,REV,DATE -f DATE=2014-04-02 AND TITLE='the hobbit' OR TITLE='the matrix'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE=2014-04-02 AND\n"
     ]
    }
   ],
   "source": [
    "# Input query string --> \"./query -s TITLE,REV,DATE -f DATE=2014-04-02 AND TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "string = str(input())\n",
    "st = Function_Param.get_string(string)\n",
    "                               \n",
    "selected_list =Function_Param.fetch_select_param(st)\n",
    "filter_list=Function_Param.fetch_filter_param(st)\n",
    "operator_list1 = Function_Param.fetch_AND_boolean_param_strval(st)\n",
    "operator_list2 = Function_Param.fetch_OR_boolean_param_strval(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./query',\n",
       "  '-s',\n",
       "  'TITLE,REV,DATE',\n",
       "  '-f',\n",
       "  'DATE=2014-04-02',\n",
       "  'AND',\n",
       "  \"TITLE='the\",\n",
       "  \"hobbit'\",\n",
       "  'OR',\n",
       "  \"TITLE='the\",\n",
       "  \"matrix'\"],\n",
       " ['TITLE', 'REV', 'DATE'],\n",
       " ['DATE=2014-04-02'],\n",
       " [\"TITLE='the hobbit'\"],\n",
       " [\"TITLE='the matrix'\"])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st,selected_list,filter_list,operator_list1,operator_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT TITLE, REV\n",
      "                   FROM media_business\n",
      "                   WHERE DATE = CAST('2014-04-02' AS date) AND (TITLE = 'the hobbit' OR TITLE = 'the matrix')\n",
      "+----------+---+\n",
      "|     TITLE|REV|\n",
      "+----------+---+\n",
      "|the hobbit|  8|\n",
      "|the matrix|  4|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qry = DML_Functions.select_advfilter_double_exp('media_business',selected_list,filter_list,operator_list1,operator_list2,'AND', 'OR')\n",
    "result = spark.sql(qry)\n",
    "print(qry)\n",
    "# Below is the result of question 2.3 with user input as \"./query -s TITLE,REV -f TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "Add a filter function which evaluates boolean AND and OR expressions in the following format:\n",
    "            STB=\"stb1\" AND TITLE=\"the hobbit\" OR TITLE=\"unbreakable\"\n",
    "            Assume AND has higher precedence than OR.  Parens can be added to change the above statement to the more logical:\n",
    "            STB=\"stb1\" AND (TITLE=\"the hobbit\" OR TITLE=\"unbreakable\")\n",
    "\n",
    "\n",
    "Advanced filter function. Using the double boolean operator  - \n",
    "Build the test case for user input -->\n",
    "\"./query -s TITLE,REV,DATE -f STB='stb1' AND TITLE='the hobbit' OR TITLE='the matrix'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STB='stb1' AND\n"
     ]
    }
   ],
   "source": [
    "# Input query string --> \"./query -s TITLE,REV,DATE -f STB='stb1' AND TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "string = str(input())\n",
    "st = Function_Param.get_string(string)\n",
    "                               \n",
    "selected_list =Function_Param.fetch_select_param(st)\n",
    "filter_list=Function_Param.fetch_filter_param(st)\n",
    "operator_list1 = Function_Param.fetch_AND_boolean_param_strval(st)\n",
    "operator_list2 = Function_Param.fetch_OR_boolean_param_strval(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_list = [\"STB='stb1'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./query',\n",
       "  '-s',\n",
       "  'TITLE,REV,DATE',\n",
       "  '-f',\n",
       "  \"STB='stb1'\",\n",
       "  'AND',\n",
       "  \"TITLE='the\",\n",
       "  \"hobbit'\",\n",
       "  'OR',\n",
       "  \"TITLE='the\",\n",
       "  \"matrix'\"],\n",
       " ['TITLE', 'REV', 'DATE'],\n",
       " [\"STB='stb1'\"],\n",
       " [\"TITLE='the hobbit'\"],\n",
       " [\"TITLE='the matrix'\"])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st,selected_list,filter_list,operator_list1,operator_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT TITLE, REV\n",
      "                   FROM media_business\n",
      "                   WHERE STB = 'stb1' AND (TITLE = 'the hobbit' OR TITLE = 'the matrix')\n",
      "+----------+---+\n",
      "|     TITLE|REV|\n",
      "+----------+---+\n",
      "|the matrix|  4|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qry = DML_Functions.select_advfilter_double_exp('media_business',selected_list,filter_list,operator_list1,operator_list2,'AND', 'OR')\n",
    "result = spark.sql(qry)\n",
    "print(qry)\n",
    "# Below is the result of question 2.3 with user input as \"./query -s TITLE,REV,DATE -f STB='stb1' AND TITLE='the hobbit' OR TITLE='the matrix'\"\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
